\documentclass{article}
\usepackage{listings}
\usepackage{array}
\usepackage[T1]{fontenc}
\lstset{breaklines=true}

\title{\textbf{Lightweight Performance Instrumentation (lwperf)}}
\author{Eric Anger - \texttt{eanger@gatech.edu}}
\date{}
\begin{document}
\maketitle
\tableofcontents
\clearpage
\section{Overview}
The Lightweight Performance Instrumentation Library (lwperf) collects performance data from applications and logs them to various backends including CSV files, to an Eiger database, or calls to Eiger models for running as a skeleton within the SST/macro simulator.

\label{sec:over}
\subsection{Introduction}
Lightweight Performance Instrumentation Library (lwperf) is a tiny collection of simple, portable functions aimed at making it easy to gather high-level compute cost numbers and the driving algorithm parameters from individual cluster nodes running real applications. The author's intended use of these numbers is to construct models that support interpolation-based estimates of compute costs at other parameter values. 

This tool is not intended to collect data for code segments containing inter-node communication code, particularly MPI code. Rather, it is intended for characterizing node-level serial, locally multi-threaded (OpenMP nests in an MPI/OMP hybrid), or locally accelerated code sections. It is usually the performance of the node or local (co)processor group in aggregate rather than individual thread performance which is of interest, as it is the group which provides the total workload to shared local resources such as memory. Single-node but multi-rank instances of MPI-only codes may also be usefully profiled with this tool. There is no technical reason lwperf cannot be used to profile MPI calls, but there are better tools for profiling MPI widely available.

\subsection{Background}
The driving need for this tool is portability: numerous superior (and heavy-weight) but proprietary performance analysis tools exist. As with mini-applications, we need mini-analysis tools.
Free MPI-oriented profiling tools already exist, but they usually stop at profiling communications and do not collect the parameters that control local workloads. Source-level insight is required to identify and capture the influential parameters.

\section{Implementation}
\label{sec:impl}
TODO: talk about how lwperf is a C library with simple functions based around the lwperf\_t* pointer.

\subsection{Dependencies}
\begin{itemize}
\item[C] Variadic macro support.
\item[Eiger] The collectors depend on libmpieiger or libmpifakeeiger if -D\_USE\_EIGER is applied. Eiger is not needed if only CSV collection is used.
\item[PAPI] \textit{OPTIONAL} The PAPI interface is used to collect hardware performance counters. This is disabled by default.
\end{itemize}

\section{Application Programming Interface}
This section documents the API for interacting with the lwperf library.

\subsection{Setup}
For C++, the profiled code must include a single header, lwperf.h, which pulls in definitions for the data collection macros based on the compiler flags: -D\_USE\_EIGER and -D\_USE\_CSV. If neither flag is provided, a set of null macros make all the collector-related code disappear from the build.
After lwperf.h is included in the driver and all files where collection is needed are listed in the updateLoggersCXX.sh script, the driver has a simple init/configure/run/finalize use sequence. 

\subsection{Profile sites}
At any site (usually a loop nest) where data collection is wanted, the collection point is defined at the beginning of the site with a unique name and additional log names for parameters characterizing the work load (usually integer). The values of the parameters do not need to be available at the beginning of the site; only names are needed. The name given the site must be unique across the entire application. The parameter names are specific to the site and may be reused elsewhere.

From a molecular dynamics example, with a variable work load where nlocal is known at the beginning but nneigh is dependent on double-precision input data arrays:
\begin{verbatim}
  PERFDECL(int nneigh=0;); // counter used only when profiling
  // site Tenergy, log parameter names nlocal, nneigh
  PERFLOG(Tenergy, ID(nlocal),ID(nneigh)); 
  for (int i = 0; i < nlocal; i++) { // outer loop
    ... // fixed work calculating, in part, data_dependent_condition
    if ( data_dependent_condition) {
      for (int j=0; j< numneigh; j++) {
        PERFDECL(nneigh+=numneigh;); // assignment needed only for profiling
        ... // conditional work
      }
    }
  }
  PERFSTOP(Tenergy, ID(atom.nlocal),ID(nneigh));
\end{verbatim}

At the end of the site, PERFSTOP computes the elapsed performance measures (at minimum, wallclock) and these values are logged along with the values passed to the slots defined in the matching PERFLOG statement. In this case the value of nlocal comes from data named atom.nlocal. The data-dependent nneigh parameter is declared and updated only when lwperf is enabled (through use of PERFDECL).

Analogous to PERFLOG/PERFSTOP are the macros PERFLOGKEEP/PERFSTOPKEEP. They function the same way as PERFLOG/PERFSTOP except with regards to skeletonization; use they macros whenever the metrics being instrumented are data-dependent, in the sense that they only have valid values as long as the actual computation is performed. When the -D\_USE\_EIGER\_MODEL flag is set, the sections of code in between calls to PERFLOGKEEP and PERFSTOPKEEP will \textit{not} be removed.

\subsection{Hardware Performance Counters}
Hardware performance counters may be collected in addition to the system clock time and used as nondeterministic metrics. lwperf uses the PAPI interface for collecting hardware performance counters, support for which is turned off by default. To use, make sure that \texttt{USE\_PAPI} is defined in the preprocessor, either setting the preprocessor flag \texttt{-DUSE\_PAPI} during compilation or by placing \texttt{#define USE\_PAPI} before including the \texttt{lwperf.h} header.

\section{Building}
Being lightweight by design, this tool is intended to be used by incorporation into the investigated application and its build processes rather than as an independent library.  In order to keep performance impact to minimum without introducing a proprietary compiler, some simple portions of the support classes must be generated based on a scan of the sites defined in the application code. This scan is performed and the generated code is updated by the simple utility {\em updateLoggersCXX.sh}. This utility takes the file names to parse as parameters.

\section{Running}
\label{sec:running}
The timing data obtainable should be reasonably accurate for measured non-overlapping compute sections, but the overall application performance may be strongly influenced by the extra I/O.

\section{Analysis}
Lwperf makes collecting large amounts of performance data easy. Analysis of the data is beyond the scope of this document. Studying the impact of application parameters and compiler options on the runtime performance of specific code segments (loop nests) requires careful construction of a set of benchmark runs spanning some relevant parameter space. The generated CSV files can be easily aggregated and then imported or translated for use in any preferred tool (a spreadsheet, gnuplot, etc).

Early use of the tool has provided one general insight. When examining the wall-clock and processor-clock time reported for a profiling site, the two measurements may differ widely due to process interruptions. The most common interruptions will be reported in the other rusage fields recorded, though these fields normally report 0 for number-crunching loops. Consult the system documentation of getrusage for explanation of the reported fields.

The default data collected includes the wall-clock time. This enables production of timelines which capture what code section was active when, not just how much time was spent in each call.

\section{Skeletonization}
Lwperf can be used in conjunction with the SST/macro simulator to facilitate the creation of application "skeletons", versions of the application fit for accelerated simulation by removing all time-intensive memory acquisition and computation. Each profiling site can be viewed as a way to replace the execution of that code with an equivalent Eiger model. Setting the compiler flag -D\_USE\_EIGER\_MODEL will remove all the code in between calls to PERFLOG and PERFSTOP, replacing them with appropriate calls to the Eiger models that would be created by running this code. Currently only C++ applications are supported. While this may not handle the entirety of the skeletonizing effort, it allows for seamless integration of Eiger models and skeleton construction. 

Skeletonization assumes a naming convention for models created with Eiger, \textit{<site name>.model}, where <site name> is the first parameter to the PERFLOG macro.

\end{document}
